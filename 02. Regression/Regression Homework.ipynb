{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1f4712",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4b73c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading dataset\n",
    "#data = 'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv'\n",
    "#wget.download(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b36fa8",
   "metadata": {},
   "source": [
    "# Problem statement\n",
    "Creating a model that would predict the house prices \"Median_house_value\"\n",
    "\n",
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767d6055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#viewing the dataframe\n",
    "df = pd.read_csv('housing.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af1749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualiding the distribution of the median_house_value\n",
    "\n",
    "sns.displot(df['median_house_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a80a277",
   "metadata": {},
   "source": [
    "The plot has some skewness in it, resulting in a longtail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb36f2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ocean_proximity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716a2d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[df['ocean_proximity'].isin(['INLAND', '<1H OCEAN'])].reset_index()\n",
    "df_filtered['ocean_proximity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e33904",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = ['latitude',\n",
    "'longitude',\n",
    "'housing_median_age',\n",
    "'total_rooms',\n",
    "'total_bedrooms',\n",
    "'population',\n",
    "'households',\n",
    "'median_income',]\n",
    "\n",
    "df_filtered[base]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9fc6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chacking the sum of the missing value in each column\n",
    "df_filtered.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419a24f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Meadian of the population\n",
    "df_filtered['population'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913c5d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5abb1a5",
   "metadata": {},
   "source": [
    "## Shuffling the index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad8aebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64074c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(n)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13a4650",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the seed to 42 for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "#shuffle the idx array\n",
    "np.random.shuffle(idx)\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca1eb54",
   "metadata": {},
   "source": [
    "splitting the data to 60% train, 20% validation, and 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1af389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we split the number before we apply them to the dataframe\n",
    "n_test = int(n *0.2)\n",
    "n_val = int(n*0.2)\n",
    "n_train = n - n_test - n_val\n",
    "\n",
    "n, n_test+n_val+n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85ff2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataframe\n",
    "df_train = df_filtered.iloc[idx[:n_train]]\n",
    "df_val = df_filtered.iloc[idx[n_train:n_train + n_val]]\n",
    "df_test = df_filtered.iloc[idx[n_train+n_val:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5093fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainsforming the target y, \"house_median_value\" to log + 1 function\n",
    "y_train = np.log1p(df_train['median_house_value']).values #getting the values in a vector form/ array\n",
    "y_test = np.log1p(df_test['median_house_value']).values\n",
    "y_val = np.log1p(df_val['median_house_value']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f6011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting the y variables from the train, test, val datafram to avoid accidentaly using them\n",
    "del df_train['median_house_value']\n",
    "del df_test['median_house_value']\n",
    "del df_val['median_house_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e67fc3f",
   "metadata": {},
   "source": [
    "- We need to deal with missing values for the column from 'total_bedrooms'.\n",
    "- We have two options: fill it with 0 or with the mean of this variable.\n",
    "- Try both options. For each, train a linear regression model without regularization.\n",
    "- For computing the mean, we'll use the training only!\n",
    "- Use the validation dataset to evaluate the models and compare the RMSE of each option.\n",
    "- Round the RMSE scores to 2 decimal digits using round(score, 2)\n",
    "- Which option gives better RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68257cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling in the missing values using the mean in the train set\n",
    "df_train_mean = df_train.fillna(df_train['total_bedrooms'].mean())\n",
    "df_test_mean = df_test.fillna(df_test['total_bedrooms'].mean())\n",
    "df_val_mean = df_val.fillna(df_val['total_bedrooms'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78568bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling in the missing values using the 0 value \n",
    "df_train_0 = df_train.fillna(0)\n",
    "df_test_0 = df_test.fillna(0)\n",
    "df_val_0 = df_val.fillna(0)\n",
    "\n",
    "df_train_0['total_bedrooms'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acd71b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping and reseting index\n",
    "df_train_mean = df_train_mean.copy()\n",
    "df_train_mean.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60c2b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['ocean_proximity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed92131",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {}\n",
    "\n",
    "for c in categorical_columns:\n",
    "    categories[c] = list(df[c].value_counts().head().index)\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048ea7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_X(df):\n",
    "    df = df.copy()\n",
    "    features = base.copy()  # Assuming base is defined somewhere in your code\n",
    "    \n",
    "    # Get the dummy columns.\n",
    "    dummies = pd.get_dummies(df['ocean_proximity'], prefix='ocean_proximity')\n",
    "    \n",
    "    # Add the dummy columns to the dataframe.\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    \n",
    "    # Drop the original categorical column\n",
    "    df = df.drop('ocean_proximity', axis=1)\n",
    "    \n",
    "    # Update features list\n",
    "    features.extend(dummies.columns.tolist())\n",
    "    \n",
    "    df_nums = df[features]\n",
    "    X = df_nums.values\n",
    "    return X \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74815243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_regression(X, y):\n",
    "    '''\n",
    "    args:\n",
    "          X - m*n matrix\n",
    "          y - m*1 matrix\n",
    "          \n",
    "    return:\n",
    "            weights\n",
    "    '''\n",
    "    ones = np.ones(X.shape[0]) #generate the ones to add in a matrix\n",
    "    X = np.column_stack([ones, X]) #adding the ones in X matrix\n",
    "    \n",
    "    XTX = X.T.dot(X)\n",
    "    XTX_inv = np.linalg.inv(XTX)\n",
    "    w = XTX_inv.dot(X.T).dot(y)\n",
    "    return w[0], w[1:] # returning the intercept/bias wieght and the feature weight(s)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03b0c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, y_pred):\n",
    "    error = y_pred - y # A\n",
    "    mse = (error ** 2).mean() # B\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b3159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and getting the weights for the dataframe filled with mean\n",
    "X_train_mean = prepare_X(df_train_mean)\n",
    "w0_mean, w_mean = train_linear_regression(X_train_mean, y_train)\n",
    "\n",
    "\n",
    "#fill in the missing data with the mean\n",
    "df_val_mean = df_val.fillna(df_train['total_bedrooms'].mean())\n",
    "X_val_mean = prepare_X(df_val_mean)\n",
    "\n",
    "#taking the weights obtained in the training set to predict the validation set\n",
    "y_pred_mean = w0_mean + X_val_mean.dot(w_mean)\n",
    "\n",
    "\n",
    "#calculating the mean root square error (rmse)\n",
    "rmse(y_pred_mean, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da83c5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and getting the weights for the dataframe filled the 0 value\n",
    "X_train_0 = prepare_X(df_train_0)\n",
    "w0_0, w_0 = train_linear_regression(X_train_0, y_train)\n",
    "\n",
    "#fill in the missing data with 0 value\n",
    "df_val_0 = df_val.fillna(0)\n",
    "X_val_0 = prepare_X(df_val_0)\n",
    "\n",
    "#taking the weights obtain in the training set to predict the validation set\n",
    "y_val_pred_0 = w0_0 + X_val_0.dot(w_0)\n",
    "\n",
    "#calculating the mean root square error(rmse)\n",
    "round(rmse(y_val_pred_0, y_val),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de29e4e",
   "metadata": {},
   "source": [
    "### Training function with regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6beaab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_regression_reg(X, y, r=0.001): #added the r to tune\n",
    "    '''\n",
    "    args:\n",
    "          X - m*n matrix\n",
    "          y - m*1 matrix\n",
    "          \n",
    "    return:\n",
    "            weights\n",
    "    '''\n",
    "    ones = np.ones(X.shape[0]) #generate the ones to add in a matrix\n",
    "    X = np.column_stack([ones, X]) #adding the ones in X matrix\n",
    "    \n",
    "    XTX = X.T.dot(X)\n",
    "    XTX = XTX + r*np.eye(XTX.shape[0])\n",
    "    \n",
    "    XTX_inv = np.linalg.inv(XTX)\n",
    "    w = XTX_inv.dot(X.T).dot(y)\n",
    "    return w[0], w[1:] # returning the intercept/bias wieght and the feature weight(s)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eb7502",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "errors = []\n",
    "\n",
    "for r in [0, 0.000001, 0.0001, 0.001, 0.01, 0.1, 1, 5, 10]:\n",
    "    w0, w = train_linear_regression_reg(X_train_0, y_train, r)\n",
    "    \n",
    "    #prediction to validation set\n",
    "    y_pred_val = w0 + X_val_0.dot(w)\n",
    "    error_term = rmse(y_pred_val, y_val)\n",
    "    \n",
    "    print('r                   error_term')\n",
    "    print(r,'               ', error_term)\n",
    "    errors.append(error_term)\n",
    "    print('------------------------------')\n",
    "    print()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98682a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the smallest error term\n",
    "min(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7409c40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_1 = df_filtered.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21fe592",
   "metadata": {},
   "source": [
    "- We used seed 42 for splitting the data. Let's find out how selecting the seed influences our score.\n",
    "- Trying different seed values: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9].\n",
    "- For each seed, do the train/validation/test split with 60%/20%/20% distribution.\n",
    "- Fill the missing values with 0 and train a model without regularization.\n",
    "- For each seed, evaluate the model on the validation dataset and collect the RMSE scores.\n",
    "- What's the standard deviation of all the scores? To compute the standard deviation, use np.std.\n",
    "- Round the result to 3 decimal digits (round(std, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9663b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with 0\n",
    "df_filtered_1 = df_filtered_1.fillna(0)\n",
    "\n",
    "# List of seed values\n",
    "seed_values = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "# Initialize an empty list to collect RMSE scores\n",
    "rmse_scores = []\n",
    "\n",
    "# Iterate over seed values\n",
    "for seed in seed_values:\n",
    "\n",
    "    # Set the seed and shuffle the data\n",
    "    np.random.seed(seed)\n",
    "    n = len(df_filtered_1)\n",
    "    idx = np.arange(n)\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    # Split the data into train, validation, and test sets\n",
    "    n_test = int(n * 0.2)\n",
    "    n_val = int(n * 0.2)\n",
    "    n_train = n - n_test - n_val\n",
    "\n",
    "    df_train = df_filtered_1.iloc[idx[:n_train]]\n",
    "    df_val = df_filtered_1.iloc[idx[n_train:n_train + n_val]]\n",
    "    df_test = df_filtered_1.iloc[idx[n_train + n_val:]]\n",
    "\n",
    "    # Get the target values for each set\n",
    "    y_train = np.log1p(df_train['median_house_value'].values)\n",
    "    y_val = np.log1p(df_val['median_house_value'].values)\n",
    "\n",
    "    # Delete the target variable from the DataFrames\n",
    "    del df_train['median_house_value']\n",
    "    del df_val['median_house_value']\n",
    "    \n",
    "    # Prepare X for train and validation sets\n",
    "    X_train = prepare_X(df_train)\n",
    "    X_val = prepare_X(df_val)\n",
    "\n",
    "    # Train a model without regularization and get weights\n",
    "    w0, w = train_linear_regression_reg(X_train, y_train)\n",
    "\n",
    "    # Predict on validation set\n",
    "    y_pred_val = w0 + X_val.dot(w)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse_1 = rmse(y_pred_val, y_val)\n",
    "    rmse_scores.append(rmse_1)\n",
    "\n",
    "# Calculate standard deviation of RMSE scores\n",
    "std_dev = np.std(rmse_scores)\n",
    "\n",
    "# Round the result to 3 decimal digits\n",
    "std_dev = round(std_dev, 3)\n",
    "\n",
    "print(f\"The standard deviation of RMSE scores is: {std_dev}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "36763cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with 0\n",
    "df2= df.fillna(0)\n",
    "\n",
    "# Set the seed and shuffle the data\n",
    "seed = 9\n",
    "np.random.seed(seed)\n",
    "n = len(df2)\n",
    "idx = np.arange(n)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "n_test = int(n * 0.2)\n",
    "n_val = int(n * 0.2)\n",
    "n_train = n - n_test - n_val\n",
    "\n",
    "df_train_2 = df2.iloc[idx[:n_train]]\n",
    "df_val_2 = df2.iloc[idx[n_train:n_train + n_val]]\n",
    "df_test_2 = df2.iloc[idx[n_train + n_val:]]\n",
    "\n",
    "# Combine train and validation datasets\n",
    "df_train_val = pd.concat([df_train_2, df_val_2], axis=0)\n",
    "\n",
    "# Get the target values for each set\n",
    "y_train_val = np.log1p(df_train_val['median_house_value'].values)\n",
    "y_test = np.log1p(df_test_2['median_house_value'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd379caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the target variable from the DataFrames\n",
    "del df_train_val['median_house_value']\n",
    "del df_test['median_house_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2df3b1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE on the test dataset is: 0.33278932696231767\n"
     ]
    }
   ],
   "source": [
    "# Prepare X for train and validation sets\n",
    "X_train_val = prepare_X(df_train_val)\n",
    "X_test = prepare_X(df_test_2)\n",
    "\n",
    "# Train a model with regularization parameter r=0.001\n",
    "r = 0.001\n",
    "w0, w = train_linear_regression_reg(X_train_val, y_train_val, r)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_test = w0 + X_test.dot(w)\n",
    "\n",
    "# Calculate RMSE on test set\n",
    "rmse_test = rmse(y_pred_test, y_test)\n",
    "print(f\"The RMSE on the test dataset is: {rmse_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d27255c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
